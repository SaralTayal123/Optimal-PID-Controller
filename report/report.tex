\documentclass[11pt]{article}

\input{sammath.sty}

\newcommand{\mycourse}{18-660: Optimization}
\newcommand{\secnum}{A}
\newcommand{\myhwnum}{}

\renewcommand{\assignmenttype}{Final Report}
\renewcommand{\partnername}{Saral Tayal}
\renewcommand{\partnerandrew}{\textit{stayal}}

\usepackage[colorlinks=true]{hyperref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Document begins here %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\graphicspath{{./img/}}

\begin{document}
%    \headings
    \headingsshared
    
    \section{Introduction}
    
    \section{Problem Formulation} \label{sec:prob}
    \subsection{Control System} \label{sec:prob:control}
    For our simulations, we are modelling the dynamics of the car with a simple non-linear bicycle model, with the following state ($x$) and control ($u$)
%    \begin{align*} 
%        x = \begin{bmatrix}
%            p_x \\ p_y \\ \theta \\ \delta \\ v \\ \omega
%        \end{bmatrix} &&
%        u = \begin{bmatrix}
%            a \\ \dot{\delta}
%        \end{bmatrix}
%    \end{align*}
    \begin{align*} 
        x = \transbmat{p_x & p_y & \theta & \delta & v} &&
        u = \transbmat{a & \dot{\delta}}
    \end{align*}
    where $p_x, p_y$ is the position, $\theta$ is the orientation, $\delta$ is the steering angle, and $v$ is the velocity. The controls for the bike are acceleration $a$, and steering angle rate $\dot{\delta}$.
    
    In order to make the system control-affine for easy optimization, we linearize our approximate dynamics model about $X_{ref}$ and $U_{ref}$ to get the following Jacobians for each step $k \in [1, N] $ in the trajectory:
    \begin{align*}
        A_k = \frac{\partial f}{\partial x}\bigg|_{x_{ref,k},u_{ref,k}} && 
        B_k = \frac{\partial f}{\partial u}\bigg|_{x_{ref,k},u_{ref,k}}
    \end{align*}
    where $f(x,u)$ is our approximate discrete dynamics model, $X_{ref}$ is the optimal trajectory computed offline with approximate dynamics model, and $U_{ref}$ is the optimal controls computed offline with approximate dynamics model. \\
%    - $X_{sim}$ (`Xsim`) -  Simulated trajectory with real dynamics model.
    With this, the system becomes control-affine, where the states are given by
    \begin{align*}
        x_{k+1} = A_k x_k + B_k u_k
    \end{align*}
    and the proportional-derivative (PD) controller gives the control
    \begin{align*}
        u_k = - \left[\strut P * \left(x_{k} - x_{ref,k}\right) + D (x_k - x_{k-1}) \strut \right]
    \end{align*}
    where $P,D$ are the proportional and derivative control matrices to be found by our algorithm.
    
    \pagebreak
    
    \subsection{Optimizing for PD matrices} \label{sec:prob:pdoptim}
    In order to automatically tune the PD matrices, we optimize for best PD matrices that minimize the quadratic cost of the trajectory generated by the PID controller, as constrained by control-affine system dynamics. Mathematically, we attempt to solve the following problem:
    \begin{align*}
        \min_{P,D}\qquad & \mathrm{Cost}(X, X_{ref}) \fracln
        \st \quad & x_1 = x_{ref, 1} \vecln
        &         x_{k+1} = A_k x_k + B_k u_k \vecln
        &         u_k = - \left[\strut P * \left(x_{k} - x_{ref,k}\right) + D (x_k - x_{k-1}) \strut \right]
    \end{align*}
    where $X, X_{ref}$ are the generated and reference trajectories respectively (a direct function of the states $x_k$), and $A_k, B_k$ are the Jacobians representing the linearized system dynamics as mentioned in Section \ref{sec:prob:control} above.
    
    \subsubsection{Without Regularization} \label{sec:prob:pdoptim:noreg}
    Our initial formulation without regularization involved a simple quadratic cost.
    \begin{align*}
        \mathrm{Cost}(X, X_{ref}) = \transp{X - X_{ref}} Q \left(X - X_{ref}\right)
    \end{align*}
    where $Q \curlygeq 0 $ is a quadratic cost matrix. Since the cost function is quadratic and the constraints are affine, we have a quadratic programming problem, which can be solved efficiently as noted in class.
    
    \subsection{With Regularization} \label{sec:prob:pdoptim:wreg}
    However, as noted in Section \ref{sec:results:singletraj:noreg}, the simple formulation results in exploding P and D values. To combat this, we add L1 regularization to the quadratic cost as follows:
    \begin{align*}
        \mathrm{Cost}(X, X_{ref}) = \transp{X - X_{ref}} Q \left(X - X_{ref}\right) + \lambda \left(\strut \norm{P}_1 + \norm{D}_1 \strut \right)
    \end{align*}
    where $\lambda$ is a hyperparameter that affects the amount of regularization in the system. Although the L1 regularization makes the problem no longer quadratic, the problem is still convex and can be solved quite efficiently by proximal gradient descent.
    
    \section{Results} \label{sec:results}
    \subsection{Single trajectory} \label{sec:results:singletraj}
    Saral setup a simulation architecture in Julia with a preset trajectory to control a car with bicycle dynamics, while Samuel worked on the problem formulation and metrics. The code can be found at \href{https://github.com/SaralTayal123/OptimizationFinalProj}{https://github.com/SaralTayal123/OptimizationFinalProj}. We started with a single parabolic trajectory, shown in Figure \ref{fig:trajectory} below.
    
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.5\linewidth]{trajectory}
        \caption{Simple parabolic trajectory for robot to follow}
        \label{fig:trajectory}
    \end{figure}

    \subsubsection{Metrics} \label{sec:results:metrics}
    \textbf{TODO: Include metrics here, with references}

    \subsubsection{Without Regularization} \label{sec:results:singletraj:noreg}
    With the simple non-regularized quadratic cost, we found that our P/D matrices had very large values as shown below, and caused the optimizer to fail completely with infinite values for all metrics
        \begin{align*}
            \hspace{-2em}
            P &= \bmat{-25.48 & -43.88 & 228.95 & 904.98 & 1151.69 \\
                -1.81 & -4.19 & 29.26 & -70.38 & -26.2} && 
            D &
            = \bmat{-130.93 & -71.37 & -1142.36 & 22.02 & 2424.28 \\
                -9.39 & 10.48  & -19.01 & 3.23 & 186.85}
        \end{align*}
    
    \subsubsection{With Regularization} \label{sec:results:singletraj:wreg}
        \begin{align*}
%            \hspace{-2em}
            P &= \bmat{-0.79 & 0.11 & 0 & 0 & 0 \\ -0.22 & -0.08 & 0 & 0 & 0} && 
            D &= \bmat{-0.42 & 0 & 0 & 0 & 0 \\  0.2 & 0 & 0 & 0 & 0}
        \end{align*}
    
    \section{Learning Objectives}
    In this project, we originally set out to learn more about optimal control and how optimization can be applied to the field. 
    This project was a indeed good opportunity (especially for Samuel who was more new to the field) to learn more about optimal control theory, particularly dynamics and trajectory optimization. A bigger part of our learning process involved trying to formulate our optimization problem, using what we learnt in class. Since dynamics-aware and trajectory-aware control problems can be quite complicated, it was challenging to do so in a way that was intuitive, while staying convex and easily solvable. Originally, we had wanted to autotune Q/R matrices for optimal control, but quickly found that the formulation was too complex; eventually, we simplified the problem by focusing on PID control and autotuning (optimizing for) P/D matrices. Still, formulating the optimization problem from scratch was not exactly non-trivial, but we used the techniques learnt in class to do it. In particular, we first tried a quadratic cost function with linear constraints to formulate a simple quadratic programming problem, and when that cause the values to explode, we turned to L1 regularization, which worked very well. 
\end{document}

